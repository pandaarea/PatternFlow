{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8490b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df0d21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9ae81",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800d97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a855bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = sorted(tf.io.gfile.glob('./ISIC2018_Task1-2_Training_Input_x2/*.jpg'))\n",
    "ground_truth = sorted(tf.io.gfile.glob('./ISIC2018_Task1_Training_GroundTruth_x2/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13f2fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\ISIC2018_Task1-2_Training_Input_x2\\\\ISIC_0000000.jpg',\n",
       " '.\\\\ISIC2018_Task1-2_Training_Input_x2\\\\ISIC_0000001.jpg',\n",
       " '.\\\\ISIC2018_Task1-2_Training_Input_x2\\\\ISIC_0000003.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_input[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e11b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\ISIC2018_Task1_Training_GroundTruth_x2\\\\ISIC_0000000_segmentation.png',\n",
       " '.\\\\ISIC2018_Task1_Training_GroundTruth_x2\\\\ISIC_0000001_segmentation.png',\n",
       " '.\\\\ISIC2018_Task1_Training_GroundTruth_x2\\\\ISIC_0000003_segmentation.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8ce11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594\n",
      "518\n",
      "518\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset into training set, test set and val set with 6：2：2\n",
    "length = len(image_input)\n",
    "print(length)\n",
    "\n",
    "image_input_val = image_input[:(int(length*0.2))]\n",
    "print(len(image_input_val))\n",
    "ground_truth_val = ground_truth[:(int(length*0.2))]\n",
    "print(len(ground_truth_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111f5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input_test = image_input[int(length*0.2):int(length*0.4)]\n",
    "ground_truth_test = ground_truth[int(length*0.2):int(length*0.4)]\n",
    "\n",
    "image_input_train = image_input[int(length*0.4):]\n",
    "ground_truth_train = ground_truth[int(length*0.4):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b710902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1557\n",
      "1557\n"
     ]
    }
   ],
   "source": [
    "print(len(image_input_train))\n",
    "print(len(ground_truth_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0f4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((image_input_train, ground_truth_train))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((image_input_val, ground_truth_val))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((image_input_test, ground_truth_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c4b0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing function\n",
    "def processing_jpg(path):\n",
    "    \n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (256, 256))\n",
    "    \n",
    "    return image\n",
    "  \n",
    "def processing_png(path):\n",
    "    \n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, (256, 256))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b92d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize function\n",
    "def normal(image, ground):\n",
    "    \n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    ground = tf.cast(ground, tf.float32) / 255.0\n",
    "    \n",
    "    return image, ground\n",
    "\n",
    "def load_image(image_path, ground_path):\n",
    "    \n",
    "    image = processing_jpg(image_path)\n",
    "    ground = processing_png(ground_path)\n",
    "    image, ground = normal(image, ground)\n",
    "\n",
    "    return image, ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5156c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(load_image)\n",
    "val_ds = val_ds.map(load_image)\n",
    "test_ds = test_ds.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f540441",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33aea67",
   "metadata": {},
   "source": [
    "## Build improved Unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b6396f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_module(input_layer, filters):\n",
    "    \n",
    "    norm_1 = tfa.layers.InstanceNormalization()(input_layer)\n",
    "    conv_1 = keras.layers.Conv2D(filters, (3, 3), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(norm_1)\n",
    "    drop_layer = keras.layers.Dropout(0.3)(conv_1)\n",
    "    norm_2 = tfa.layers.InstanceNormalization()(drop_layer)\n",
    "    conv_2 = keras.layers.Conv2D(filters, (3, 3), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(norm_2)\n",
    "\n",
    "    return conv_2\n",
    "\n",
    "def upsampling(input_layer, filters):\n",
    "    \n",
    "    up_layer = keras.layers.UpSampling2D((2, 2))(input_layer)\n",
    "    up_layer_2 = keras.layers.Conv2D(filters, (3, 3), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(up_layer)\n",
    "    norm_1 = tfa.layers.InstanceNormalization()(up_layer_2)\n",
    "    \n",
    "    return norm_1\n",
    "\n",
    "def localization_module(input_layer, filters):\n",
    "    \n",
    "    conv_1 = keras.layers.Conv2D(filters, (3, 3), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(input_layer)\n",
    "    norm_1 = tfa.layers.InstanceNormalization()(conv_1)\n",
    "    conv_2 = keras.layers.Conv2D(filters, (1, 1), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(norm_1)\n",
    "    norm_2 = tfa.layers.InstanceNormalization()(conv_2)\n",
    "    \n",
    "\n",
    "    return norm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add86d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
