{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c52b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61995f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0097d",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1aa9f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6244b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = sorted(tf.io.gfile.glob('./ISIC2018_Task1-2_Training_Input_x2/*.jpg'))\n",
    "ground_truth = sorted(tf.io.gfile.glob('./ISIC2018_Task1_Training_GroundTruth_x2/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89f52282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\ISIC2018_Task1-2_Training_Input_x2\\\\ISIC_0000000.jpg',\n",
       " '.\\\\ISIC2018_Task1-2_Training_Input_x2\\\\ISIC_0000001.jpg',\n",
       " '.\\\\ISIC2018_Task1-2_Training_Input_x2\\\\ISIC_0000003.jpg']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_input[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5802cc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\ISIC2018_Task1_Training_GroundTruth_x2\\\\ISIC_0000000_segmentation.png',\n",
       " '.\\\\ISIC2018_Task1_Training_GroundTruth_x2\\\\ISIC_0000001_segmentation.png',\n",
       " '.\\\\ISIC2018_Task1_Training_GroundTruth_x2\\\\ISIC_0000003_segmentation.png']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f296a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.permutation(len(image_input))\n",
    "image_input = np.array(image_input)[index]\n",
    "ground_truth = np.array(ground_truth)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7367cfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.\\\\ISIC2018_Task1-2_Training_Input_x2\\\\ISIC_0012266.jpg',\n",
       "       '.\\\\ISIC2018_Task1-2_Training_Input_x2\\\\ISIC_0014825.jpg',\n",
       "       '.\\\\ISIC2018_Task1-2_Training_Input_x2\\\\ISIC_0006612.jpg'],\n",
       "      dtype='<U53')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_input[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "20545ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['.\\\\ISIC2018_Task1_Training_GroundTruth_x2\\\\ISIC_0012266_segmentation.png',\n",
       "       '.\\\\ISIC2018_Task1_Training_GroundTruth_x2\\\\ISIC_0014825_segmentation.png',\n",
       "       '.\\\\ISIC2018_Task1_Training_GroundTruth_x2\\\\ISIC_0006612_segmentation.png'],\n",
       "      dtype='<U70')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "50506a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594\n",
      "518\n",
      "518\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset into training set, test set and val set with 6：2：2\n",
    "length = len(image_input)\n",
    "print(length)\n",
    "\n",
    "image_input_val = image_input[:(int(length*0.2))]\n",
    "print(len(image_input_val))\n",
    "ground_truth_val = ground_truth[:(int(length*0.2))]\n",
    "print(len(ground_truth_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40ddc533",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input_test = image_input[int(length*0.2):int(length*0.3)]\n",
    "ground_truth_test = ground_truth[int(length*0.2):int(length*0.3)]\n",
    "\n",
    "image_input_train = image_input[int(length*0.3):]\n",
    "ground_truth_train = ground_truth[int(length*0.3):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f186b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1816\n",
      "1816\n"
     ]
    }
   ],
   "source": [
    "print(len(image_input_train))\n",
    "print(len(ground_truth_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8294031",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((image_input_train, ground_truth_train))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((image_input_val, ground_truth_val))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((image_input_test, ground_truth_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2d9b8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing function\n",
    "# Limited by the  memory of the GPU, choose the image size of 192, 192\n",
    "def processing_jpg(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (192, 192))\n",
    "    \n",
    "    return image\n",
    "  \n",
    "def processing_png(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, (192, 192))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14974ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize function\n",
    "def normal(image, ground):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    ground = tf.cast(ground, tf.float32) / 255.0\n",
    "    \n",
    "    return image, ground\n",
    "\n",
    "def load_image(image_path, ground_path):\n",
    "    image = processing_jpg(image_path)\n",
    "    ground = processing_png(ground_path)\n",
    "    image, ground = normal(image, ground)\n",
    "\n",
    "    return image, ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8c7b6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(load_image)\n",
    "val_ds = val_ds.map(load_image)\n",
    "test_ds = test_ds.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e79bfb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30f337",
   "metadata": {},
   "source": [
    "## Build improved Unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fc630be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_module(input_layer, filters):\n",
    "    norm_1 = tfa.layers.InstanceNormalization()(input_layer)\n",
    "    conv_1 = keras.layers.Conv2D(filters, (3, 3), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(norm_1)\n",
    "    drop_layer = keras.layers.Dropout(0.3)(conv_1)\n",
    "    norm_2 = tfa.layers.InstanceNormalization()(drop_layer)\n",
    "    conv_2 = keras.layers.Conv2D(filters, (3, 3), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(norm_2)\n",
    "\n",
    "    return conv_2\n",
    "\n",
    "def upsampling_module(input_layer, filters):\n",
    "    up_layer = keras.layers.UpSampling2D((2, 2))(input_layer)\n",
    "    up_layer_2 = keras.layers.Conv2D(filters, (3, 3), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(up_layer)\n",
    "    norm_1 = tfa.layers.InstanceNormalization()(up_layer_2)\n",
    "    \n",
    "    return norm_1\n",
    "\n",
    "def localization_module(input_layer, filters):\n",
    "    conv_1 = keras.layers.Conv2D(filters, (3, 3), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(input_layer)\n",
    "    norm_1 = tfa.layers.InstanceNormalization()(conv_1)\n",
    "    conv_2 = keras.layers.Conv2D(filters, (1, 1), padding = \"same\", activation = keras.layers.LeakyReLU(alpha = 0.01))(norm_1)\n",
    "    norm_2 = tfa.layers.InstanceNormalization()(conv_2)\n",
    "\n",
    "    return norm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0b93e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth = 1.0):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    dice_coef_result = (2.0 * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "    return dice_coef_result\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e20eefa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_model():\n",
    "    input_size = (192, 192, 3)\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=(input_size))\n",
    "    # Down-sampling\n",
    "    # layer 1\n",
    "    # 3x3x3 convolution_1\n",
    "    conv_1 = keras.layers.Conv2D(16, kernel_size=(3,3), padding=\"same\")(input_layer)\n",
    "    # context_module_1\n",
    "    context_module_1 = context_module(conv_1, 16)\n",
    "    # element-wise sum\n",
    "    sum_1 = keras.layers.Add()([conv_1, context_module_1])\n",
    "    \n",
    "    # layer 2\n",
    "    conv_2 = keras.layers.Conv2D(32, kernel_size=(3,3), padding=\"same\", strides=(2,2))(sum_1)\n",
    "    context_module_2 = context_module(conv_2, 32)\n",
    "    sum_2 = keras.layers.Add()([conv_2, context_module_2])\n",
    "    \n",
    "    # layer 3\n",
    "    conv_3 = keras.layers.Conv2D(64, kernel_size=(3,3), padding=\"same\", strides=(2,2))(sum_2)\n",
    "    context_module_3 = context_module(conv_3, 64)\n",
    "    sum_3 = keras.layers.Add()([conv_3, context_module_3])\n",
    "    \n",
    "    # layer 4\n",
    "    conv_4 = keras.layers.Conv2D(128, kernel_size=(3,3), padding=\"same\", strides=(2,2))(sum_3)\n",
    "    context_module_4 = context_module(conv_4, 128)\n",
    "    sum_4 = keras.layers.Add()([conv_4, context_module_4])\n",
    "    \n",
    "    # layer 5\n",
    "    conv_5 = keras.layers.Conv2D(256, kernel_size=(3,3), padding=\"same\", strides=(2,2))(sum_4)\n",
    "    context_module_5 = context_module(conv_5, 256)\n",
    "    sum_5 = keras.layers.Add()([conv_5, context_module_5])\n",
    "    \n",
    "    # localization \n",
    "    up_sampling_1 = upsampling_module(sum_5, 128)\n",
    "    concat_1 = keras.layers.Concatenate()([up_sampling_1, sum_4])\n",
    "    \n",
    "    \n",
    "    # Up-sampling\n",
    "    # layer 4\n",
    "    localization_1 = localization_module(concat_1, 128)\n",
    "    up_sampling_2 = upsampling_module(localization_1, 64)\n",
    "    \n",
    "    # layer 3\n",
    "    concatenation_2 = keras.layers.Concatenate()([up_sampling_2, sum_3])\n",
    "    localization_2 = localization_module(concatenation_2, 64)\n",
    "    segmentation_1 = keras.layers.Conv2D(1, (1,1), padding=\"same\", activation=keras.layers.LeakyReLU(alpha=0.01))(localization_2)\n",
    "    up_sampling_3 = upsampling_module(localization_2, 32)\n",
    "    \n",
    "    # layer 2\n",
    "    concatenation_3 = keras.layers.Concatenate()([up_sampling_3, sum_2])\n",
    "    localization_3 = localization_module(concatenation_3, 32)\n",
    "    segmentation_2 = keras.layers.Conv2D(1, (1,1), padding=\"same\", activation=keras.layers.LeakyReLU(alpha=0.01))(localization_3)\n",
    "    up_sampling_4 = upsampling_module(localization_3, 16)\n",
    "    up_sampling_segament_1 = keras.layers.UpSampling2D(size=(2,2))(segmentation_1)\n",
    "    \n",
    "    sum_sum_1 = keras.layers.Add()([up_sampling_segament_1, segmentation_2])\n",
    "    \n",
    "    # layer 1\n",
    "    concatenation_4 = keras.layers.Concatenate()([up_sampling_4, sum_1])\n",
    "    conv_6 = keras.layers.Conv2D(32, kernel_size=(3,3), padding=\"same\", activation=keras.layers.LeakyReLU(alpha=0.01))(concatenation_4)\n",
    "    segmentation_3 = keras.layers.Conv2D(1, (1,1), padding=\"same\", activation=keras.layers.LeakyReLU(alpha=0.01))(conv_6)\n",
    "    \n",
    "    up_sampling_segament_2 = keras.layers.UpSampling2D(size=(2,2))(sum_sum_1)\n",
    "    sum_segmentation = keras.layers.Add()([up_sampling_segament_2, segmentation_3])\n",
    "    output_layer = keras.layers.Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid', padding='same')(sum_segmentation)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c75d7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = improved_model()\n",
    "model.compile(optimizer=\"adam\", loss=dice_coef_loss, metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "904a7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "87ba32db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/57 [==============================] - 14s 184ms/step - loss: 0.5289 - dice_coef: 0.4715 - val_loss: 0.5002 - val_dice_coef: 0.5043\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.3805 - dice_coef: 0.6205 - val_loss: 0.2287 - val_dice_coef: 0.7753\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1914 - dice_coef: 0.8090 - val_loss: 0.1675 - val_dice_coef: 0.8350\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 10s 173ms/step - loss: 0.1577 - dice_coef: 0.8426 - val_loss: 0.1591 - val_dice_coef: 0.8435\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.1420 - dice_coef: 0.8583 - val_loss: 0.1530 - val_dice_coef: 0.8473\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1349 - dice_coef: 0.8653 - val_loss: 0.1311 - val_dice_coef: 0.8707\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1252 - dice_coef: 0.8751 - val_loss: 0.1274 - val_dice_coef: 0.8741\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1212 - dice_coef: 0.8790 - val_loss: 0.1321 - val_dice_coef: 0.8694\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1159 - dice_coef: 0.8843 - val_loss: 0.1335 - val_dice_coef: 0.8676\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1115 - dice_coef: 0.8887 - val_loss: 0.1282 - val_dice_coef: 0.8728\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1098 - dice_coef: 0.8903 - val_loss: 0.1207 - val_dice_coef: 0.8815\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1359 - dice_coef: 0.8644 - val_loss: 0.1307 - val_dice_coef: 0.8720\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1116 - dice_coef: 0.8886 - val_loss: 0.1196 - val_dice_coef: 0.8825\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1121 - dice_coef: 0.8881 - val_loss: 0.1209 - val_dice_coef: 0.8805\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0983 - dice_coef: 0.9019 - val_loss: 0.1168 - val_dice_coef: 0.8850\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1003 - dice_coef: 0.8999 - val_loss: 0.1163 - val_dice_coef: 0.8855\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.0975 - dice_coef: 0.9026 - val_loss: 0.1239 - val_dice_coef: 0.8777\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1032 - dice_coef: 0.8970 - val_loss: 0.1184 - val_dice_coef: 0.8828\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 10s 175ms/step - loss: 0.0922 - dice_coef: 0.9079 - val_loss: 0.1180 - val_dice_coef: 0.8843\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 10s 174ms/step - loss: 0.1008 - dice_coef: 0.8994 - val_loss: 0.1163 - val_dice_coef: 0.8852\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data = val_ds, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9080baee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
